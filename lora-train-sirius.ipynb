{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-15T08:45:16.680244Z",
     "iopub.status.busy": "2025-11-15T08:45:16.680088Z",
     "iopub.status.idle": "2025-11-15T08:46:59.720394Z",
     "shell.execute_reply": "2025-11-15T08:46:59.719475Z",
     "shell.execute_reply.started": "2025-11-15T08:45:16.680228Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.12/site-packages (0.24.1)\n",
      "Requirement already satisfied: torchaudio in ./.venv/lib/python3.12/site-packages (2.9.1)\n",
      "Collecting trl\n",
      "  Using cached trl-0.25.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting peft\n",
      "  Using cached peft-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: accelerate in ./.venv/lib/python3.12/site-packages (1.11.0)\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.11.3-py3-none-any.whl.metadata (61 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.12/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from torchvision) (2.3.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.12/site-packages (from torchvision) (12.0.0)\n",
      "Collecting datasets>=3.0.0 (from trl)\n",
      "  Using cached datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: transformers>=4.56.1 in ./.venv/lib/python3.12/site-packages (from trl) (4.57.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from peft) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from peft) (6.0.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: safetensors in ./.venv/lib/python3.12/site-packages (from peft) (0.6.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in ./.venv/lib/python3.12/site-packages (from peft) (0.36.0)\n",
      "Collecting unsloth_zoo>=2025.11.4 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.11.4-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting wheel>=0.42.0 (from unsloth)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting tyro (from unsloth)\n",
      "  Using cached tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting protobuf (from unsloth)\n",
      "  Using cached protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Using cached xformers-0.0.33.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
      "  Using cached sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting datasets>=3.0.0 (from trl)\n",
      "  Using cached datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Using cached hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Using cached diffusers-0.35.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting trl\n",
      "  Using cached trl-0.23.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets>=3.0.0->trl)\n",
      "  Using cached pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets>=3.0.0->trl)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets>=3.0.0->trl)\n",
      "  Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in ./.venv/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (0.28.1)\n",
      "Collecting xxhash (from datasets>=3.0.0->trl)\n",
      "  Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=3.0.0->trl)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers>=4.56.1->trl) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.12/site-packages (from transformers>=4.56.1->trl) (0.22.1)\n",
      "Collecting torchao>=0.13.0 (from unsloth_zoo>=2025.11.4->unsloth)\n",
      "  Using cached torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.11.4->unsloth)\n",
      "  Using cached cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting msgspec (from unsloth_zoo>=2025.11.4->unsloth)\n",
      "  Using cached msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Using cached xformers-0.0.33-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "  Using cached xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
      "  Using cached xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
      "  Using cached xformers-0.0.31.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
      "  Using cached xformers-0.0.31-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "  Using cached xformers-0.0.30-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "  Using cached xformers-0.0.29.post3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "INFO: pip is still looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached xformers-0.0.29.post2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "  Using cached xformers-0.0.29.post1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "  Using cached xformers-0.0.29-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "  Using cached xformers-0.0.28.post3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "  Using cached xformers-0.0.28.post2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached xformers-0.0.28.post1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "  Using cached xformers-0.0.28-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "  Using cached xformers-0.0.27.post2-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting trl\n",
      "  Using cached trl-0.22.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.11.2-py3-none-any.whl.metadata (61 kB)\n",
      "Collecting unsloth_zoo>=2025.11.3 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.11.3-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.11.1-py3-none-any.whl.metadata (61 kB)\n",
      "Collecting unsloth_zoo>=2025.11.1 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.11.2-py3-none-any.whl.metadata (32 kB)\n",
      "  Using cached unsloth_zoo-2025.11.1-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.10.12-py3-none-any.whl.metadata (61 kB)\n",
      "Collecting unsloth_zoo>=2025.10.13 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.10.13-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.10.11-py3-none-any.whl.metadata (61 kB)\n",
      "Collecting unsloth_zoo>=2025.10.12 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.10.12-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.10.10-py3-none-any.whl.metadata (61 kB)\n",
      "Collecting transformers>=4.56.1 (from trl)\n",
      "  Using cached transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting unsloth_zoo>=2025.10.11 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.10.11-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.10.9-py3-none-any.whl.metadata (59 kB)\n",
      "Collecting unsloth_zoo>=2025.10.10 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.10.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.10.8-py3-none-any.whl.metadata (59 kB)\n",
      "Collecting unsloth_zoo>=2025.10.9 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.10.9-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.10.7-py3-none-any.whl.metadata (59 kB)\n",
      "Collecting unsloth_zoo>=2025.10.8 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.10.8-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mistral_common (from unsloth_zoo>=2025.10.8->unsloth)\n",
      "  Using cached mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.10.6-py3-none-any.whl.metadata (59 kB)\n",
      "Collecting unsloth_zoo>=2025.10.6 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.10.7-py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached unsloth_zoo-2025.10.6-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.10.5-py3-none-any.whl.metadata (59 kB)\n",
      "Collecting unsloth_zoo>=2025.10.5 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.10.5-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.10.4-py3-none-any.whl.metadata (59 kB)\n",
      "Collecting unsloth_zoo>=2025.10.4 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.10.4-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.10.3-py3-none-any.whl.metadata (59 kB)\n",
      "Collecting unsloth_zoo>=2025.10.2 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.10.3-py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached unsloth_zoo-2025.10.2-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.10.2-py3-none-any.whl.metadata (59 kB)\n",
      "  Using cached unsloth-2025.10.1-py3-none-any.whl.metadata (53 kB)\n",
      "Collecting unsloth_zoo>=2025.10.1 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.10.1-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.9.11-py3-none-any.whl.metadata (55 kB)\n",
      "Collecting unsloth_zoo>=2025.9.13 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.9.14-py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached unsloth_zoo-2025.9.13-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.9.10-py3-none-any.whl.metadata (55 kB)\n",
      "  Using cached unsloth-2025.9.9-py3-none-any.whl.metadata (55 kB)\n",
      "Collecting datasets>=3.0.0 (from trl)\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting trl\n",
      "  Using cached trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting unsloth_zoo>=2025.9.10 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.9.12-py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached unsloth_zoo-2025.9.11-py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached unsloth_zoo-2025.9.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.9.8-py3-none-any.whl.metadata (55 kB)\n",
      "  Using cached unsloth-2025.9.7-py3-none-any.whl.metadata (54 kB)\n",
      "INFO: pip is looking at multiple versions of unsloth to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached unsloth-2025.9.6-py3-none-any.whl.metadata (54 kB)\n",
      "  Using cached unsloth-2025.9.5-py3-none-any.whl.metadata (54 kB)\n",
      "Collecting unsloth_zoo>=2025.9.6 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.9.9-py3-none-any.whl.metadata (31 kB)\n",
      "INFO: pip is looking at multiple versions of unsloth-zoo to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached unsloth_zoo-2025.9.8-py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached unsloth_zoo-2025.9.7-py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached unsloth_zoo-2025.9.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.9.4-py3-none-any.whl.metadata (52 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=3.0.0->trl)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting trl\n",
      "  Using cached trl-0.23.1-py3-none-any.whl.metadata (11 kB)\n",
      "INFO: pip is still looking at multiple versions of unsloth-zoo to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting unsloth_zoo>=2025.9.5 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.9.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.9.3-py3-none-any.whl.metadata (52 kB)\n",
      "Collecting unsloth_zoo>=2025.9.4 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.9.4-py3-none-any.whl.metadata (9.5 kB)\n",
      "INFO: pip is still looking at multiple versions of unsloth to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.9.2-py3-none-any.whl.metadata (52 kB)\n",
      "Collecting unsloth_zoo>=2025.9.3 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.9.3-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.9.1-py3-none-any.whl.metadata (52 kB)\n",
      "Collecting unsloth_zoo>=2025.9.1 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.9.2-py3-none-any.whl.metadata (9.5 kB)\n",
      "  Using cached unsloth_zoo-2025.9.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.8.10-py3-none-any.whl.metadata (52 kB)\n",
      "Collecting unsloth_zoo>=2025.8.9 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.8.9-py3-none-any.whl.metadata (9.5 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.8.9-py3-none-any.whl.metadata (52 kB)\n",
      "Collecting unsloth_zoo>=2025.8.8 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.8.8-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.8.8-py3-none-any.whl.metadata (52 kB)\n",
      "Collecting unsloth_zoo>=2025.8.7 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.8.7-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.8.7-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.8.6 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.8.6-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.8.6-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.8.5 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.8.5-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.8.5-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.8.4 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.8.4-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.8.4-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.8.3 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.8.3-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.8.3-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.8.1 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.8.2-py3-none-any.whl.metadata (9.4 kB)\n",
      "  Using cached unsloth_zoo-2025.8.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.8.2-py3-none-any.whl.metadata (47 kB)\n",
      "  Using cached unsloth-2025.8.1-py3-none-any.whl.metadata (47 kB)\n",
      "  Using cached unsloth-2025.7.11-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.7.11 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.7.11-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.7.10-py3-none-any.whl.metadata (47 kB)\n",
      "  Using cached unsloth-2025.7.8-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.7.9 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.7.10-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached unsloth_zoo-2025.7.9-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.7.7-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.7.8 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.7.8-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.7.6-py3-none-any.whl.metadata (47 kB)\n",
      "  Using cached unsloth-2025.7.5-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.7.7 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.7.7-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.7.4-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.7.5 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.7.6-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached unsloth_zoo-2025.7.5-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.7.3-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.7.4 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.7.4-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting protobuf (from unsloth)\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.7.2-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.7.2 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.7.3-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached unsloth_zoo-2025.7.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.7.1-py3-none-any.whl.metadata (47 kB)\n",
      "  Using cached unsloth-2025.6.12-py3-none-any.whl.metadata (46 kB)\n",
      "  Using cached unsloth-2025.6.11-py3-none-any.whl.metadata (48 kB)\n",
      "  Using cached unsloth-2025.6.10-py3-none-any.whl.metadata (48 kB)\n",
      "  Using cached unsloth-2025.6.9-py3-none-any.whl.metadata (46 kB)\n",
      "  Using cached unsloth-2025.6.8-py3-none-any.whl.metadata (46 kB)\n",
      "  Using cached unsloth-2025.6.7-py3-none-any.whl.metadata (46 kB)\n",
      "  Using cached unsloth-2025.6.6-py3-none-any.whl.metadata (46 kB)\n",
      "  Using cached unsloth-2025.6.5-py3-none-any.whl.metadata (47 kB)\n",
      "  Using cached unsloth-2025.6.4-py3-none-any.whl.metadata (47 kB)\n",
      "  Using cached unsloth-2025.6.3-py3-none-any.whl.metadata (47 kB)\n",
      "  Using cached unsloth-2025.6.2-py3-none-any.whl.metadata (47 kB)\n",
      "  Using cached unsloth-2025.6.1-py3-none-any.whl.metadata (47 kB)\n",
      "  Using cached unsloth-2025.5.9-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.5.11 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.7.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached unsloth_zoo-2025.6.8-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached unsloth_zoo-2025.6.7-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached unsloth_zoo-2025.6.6-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached unsloth_zoo-2025.6.5-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached unsloth_zoo-2025.6.4-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached unsloth_zoo-2025.6.3-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached unsloth_zoo-2025.6.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached unsloth_zoo-2025.6.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached unsloth_zoo-2025.5.11-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.5.8-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting unsloth_zoo>=2025.5.10 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.5.10-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.5.7-py3-none-any.whl.metadata (47 kB)\n",
      "  Using cached unsloth-2025.5.6-py3-none-any.whl.metadata (46 kB)\n",
      "  Using cached unsloth-2025.5.5-py3-none-any.whl.metadata (46 kB)\n",
      "  Using cached unsloth-2025.5.4-py3-none-any.whl.metadata (46 kB)\n",
      "  Using cached unsloth-2025.5.3-py3-none-any.whl.metadata (48 kB)\n",
      "  Using cached unsloth-2025.5.2-py3-none-any.whl.metadata (48 kB)\n",
      "  Using cached unsloth-2025.5.1-py3-none-any.whl.metadata (48 kB)\n",
      "  Using cached unsloth-2025.4.7-py3-none-any.whl.metadata (46 kB)\n",
      "Collecting trl\n",
      "  Using cached trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting rich (from trl)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets>=3.0.0->trl)\n",
      "  Using cached multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Collecting transformers (from peft)\n",
      "  Using cached transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting unsloth_zoo>=2025.4.4 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.5.9-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Using cached unsloth_zoo-2025.5.8-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting transformers (from peft)\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers->peft)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting unsloth_zoo>=2025.4.4 (from unsloth)\n",
      "  Using cached unsloth_zoo-2025.5.7-py3-none-any.whl.metadata (8.0 kB)\n",
      "  Using cached unsloth_zoo-2025.5.6-py3-none-any.whl.metadata (8.0 kB)\n",
      "  Using cached unsloth_zoo-2025.5.5-py3-none-any.whl.metadata (8.0 kB)\n",
      "  Using cached unsloth_zoo-2025.5.4-py3-none-any.whl.metadata (8.0 kB)\n",
      "  Using cached unsloth_zoo-2025.5.3-py3-none-any.whl.metadata (8.0 kB)\n",
      "  Using cached unsloth_zoo-2025.5.2-py3-none-any.whl.metadata (8.0 kB)\n",
      "  Using cached unsloth_zoo-2025.5.1-py3-none-any.whl.metadata (8.0 kB)\n",
      "  Using cached unsloth_zoo-2025.4.4-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting trl\n",
      "  Using cached trl-0.15.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached trl-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Using cached trl-0.13.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached trl-0.12.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting transformers (from peft)\n",
      "  Using cached transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers->peft)\n",
      "  Using cached tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting trl\n",
      "  Using cached trl-0.12.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached trl-0.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached trl-0.11.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
      "  Using cached shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Using cached typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting trl\n",
      "  Using cached trl-0.11.3-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading trl-0.11.2-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading trl-0.11.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading trl-0.11.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading trl-0.10.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting trl\n",
      "  Downloading trl-0.9.4-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading trl-0.8.5-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading trl-0.8.4-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading trl-0.8.3-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading trl-0.8.2-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading trl-0.8.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading trl-0.8.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading trl-0.7.11-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading trl-0.7.10-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading trl-0.7.9-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.4.5-py3-none-any.whl.metadata (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading unsloth-2025.4.4-py3-none-any.whl.metadata (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m782.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading unsloth-2025.4.3-py3-none-any.whl.metadata (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m938.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting unsloth_zoo>=2025.4.2 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.4.3-py3-none-any.whl.metadata (8.0 kB)\n",
      "  Downloading unsloth_zoo-2025.4.2-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.4.2-py3-none-any.whl.metadata (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m842.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading unsloth-2025.4.1-py3-none-any.whl.metadata (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m865.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting unsloth_zoo>=2025.4.1 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.4.1-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.3.19-py3-none-any.whl.metadata (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m923.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting unsloth_zoo>=2025.3.17 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.3.17-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.3.18-py3-none-any.whl.metadata (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m854.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting unsloth_zoo>=2025.3.14 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.3.16-py3-none-any.whl.metadata (8.0 kB)\n",
      "  Downloading unsloth_zoo-2025.3.15-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading unsloth_zoo-2025.3.14-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.3.17-py3-none-any.whl.metadata (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 kB\u001b[0m \u001b[31m874.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading unsloth-2025.3.16-py3-none-any.whl.metadata (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 kB\u001b[0m \u001b[31m917.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading unsloth-2025.3.15-py3-none-any.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting unsloth_zoo>=2025.3.13 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.3.13-py3-none-any.whl.metadata (17 kB)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio trl peft accelerate bitsandbytes unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T09:59:45.234390Z",
     "iopub.status.busy": "2025-11-15T09:59:45.233615Z",
     "iopub.status.idle": "2025-11-15T09:59:45.848930Z",
     "shell.execute_reply": "2025-11-15T09:59:45.848094Z",
     "shell.execute_reply.started": "2025-11-15T09:59:45.234355Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "model = \"\"\n",
    "tokenizer = \"\"\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T09:59:45.850887Z",
     "iopub.status.busy": "2025-11-15T09:59:45.850265Z",
     "iopub.status.idle": "2025-11-15T10:00:08.707964Z",
     "shell.execute_reply": "2025-11-15T10:00:08.707115Z",
     "shell.execute_reply.started": "2025-11-15T09:59:45.850868Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.11.2: Fast Qwen3 patching. Transformers: 4.57.1.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a3aadbb04f4c0fa6fd7fe386c9fe74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"RefalMachine/RuadaptQwen3-14B-Instruct\",\n",
    "    max_seq_length = 2048,\n",
    "    dtype = torch.float16,   # Указываем тип данных float16\n",
    "    load_in_4bit = False,\n",
    "    device_map=\"balanced\"\n",
    ")\n",
    "\n",
    "# Настраиваем модель для PEFT (Parameter-Efficient Fine-Tuning) с использованием LoRA.\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:00:08.709988Z",
     "iopub.status.busy": "2025-11-15T10:00:08.709194Z",
     "iopub.status.idle": "2025-11-15T10:00:09.061362Z",
     "shell.execute_reply": "2025-11-15T10:00:09.060650Z",
     "shell.execute_reply.started": "2025-11-15T10:00:08.709968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет успешно загружен. Количество записей: 123308\n",
      "Данные отформатированы с использованием chat-шаблона.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=\"/home/recsys1_user01/recipe_recommender/data-ready_lmm_train.csv\", split=\"train\")\n",
    "print(f\"Датасет успешно загружен. Количество записей: {len(dataset)}\")\n",
    "\n",
    "# Определяем неизменяемую часть промптов\n",
    "SYSTEM_PROMPT = \"\"\"Ты — ИИ-ассистент для системы продуктовых рекомендаций.\n",
    "Твоя задача — анализировать корзину и генерировать идеи для поиска недостающих товаров в виде списка поисковых запросов.\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"Контекст:\n",
    "    Текущая корзина: {current_basket}\n",
    "    Прошлые 5 покупок пользователя:\n",
    "    Прошлые 5 наиболее похожих покупок пользователя:\n",
    "### ЗАДАЧА\n",
    "На основе КОНТЕКСТА, сгенерируй не более 20 поисковых запросов, которые помогут пользователю добавить недостающие товары в корзину.\n",
    "Важные правила:\n",
    "1. Запросы должны быть краткими, отражать общие категории или идеи, а не конкретными товарами с брендом или весом.\n",
    "2. Не повторяй товары, которые уже есть в корзине.\n",
    "3. Поисковые запросы должны быть реалистичными для продуктового магазина с 10-15 тысячами наименований\n",
    "4. Вывод должен быть в формате [<запрос 1>, <запрос 2>, ...]\n",
    "\n",
    "### ПРИМЕР (для демонстрации логики, а не для копирования)\n",
    "- Пример входной корзины: [Мука пшеничная; Яйца куриные; Сахар-песок]\n",
    "- Пример правильного вывода: [\"разрыхлитель\", \"ванильный экстракт\", \"сливочное масло\", \"шоколад\", \"кондитерские украшения\"]\"\"\"\n",
    "\n",
    "def format_data_as_messages(example):\n",
    "    try:\n",
    "        input_basket_list = ast.literal_eval(example[\"input_basket\"])\n",
    "        target_basket_list = ast.literal_eval(example[\"target_basket\"])\n",
    "    except (ValueError, SyntaxError):\n",
    "        return {\"text\": None}\n",
    "\n",
    "    # 1. Собираем контент для каждого сообщения\n",
    "    current_basket_str = \"; \".join(input_basket_list)\n",
    "    user_content = USER_PROMPT_TEMPLATE.format(current_basket=current_basket_str)\n",
    "    assistant_content = str(target_basket_list)\n",
    "\n",
    "    # 2. Создаем структуру messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_content},\n",
    "    ]\n",
    "    # 3. Используем токенизатор для преобразования messages в одну строку для обучения\n",
    "    # add_generation_prompt=False, так как мы предоставляем и ответ ассистента\n",
    "    return { \"text\": tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False) }\n",
    "\n",
    "# Применяем новую функцию форматирования\n",
    "dataset = dataset.map(format_data_as_messages)\n",
    "dataset = dataset.filter(lambda example: example[\"text\"] is not None)\n",
    "print(\"Данные отформатированы с использованием chat-шаблона.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:00:09.062527Z",
     "iopub.status.busy": "2025-11-15T10:00:09.062234Z",
     "iopub.status.idle": "2025-11-15T10:00:09.068559Z",
     "shell.execute_reply": "2025-11-15T10:00:09.067816Z",
     "shell.execute_reply.started": "2025-11-15T10:00:09.062503Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipe_url': 'https://www.povarenok.ru/recipes/show/1306/',\n",
       " 'input_basket': \"['Яйцо куриное', 'Грейпфрут', 'Салат', 'Майонез']\",\n",
       " 'target_basket': \"['Сыр твердый', 'Чеснок', 'Лук зеленый']\",\n",
       " 'text': '<|im_start|>system\\nТы — ИИ-ассистент для системы продуктовых рекомендаций.\\nТвоя задача — анализировать корзину и генерировать идеи для поиска недостающих товаров в виде списка поисковых запросов.<|im_end|>\\n<|im_start|>user\\nКонтекст:\\n    Текущая корзина: Яйцо куриное; Грейпфрут; Салат; Майонез\\n    Прошлые 5 покупок пользователя:\\n    Прошлые 5 наиболее похожих покупок пользователя:\\n### ЗАДАЧА\\nНа основе КОНТЕКСТА, сгенерируй не более 20 поисковых запросов, которые помогут пользователю добавить недостающие товары в корзину.\\nВажные правила:\\n1. Запросы должны быть краткими, отражать общие категории или идеи, а не конкретными товарами с брендом или весом.\\n2. Не повторяй товары, которые уже есть в корзине.\\n3. Поисковые запросы должны быть реалистичными для продуктового магазина с 10-15 тысячами наименований\\n4. Вывод должен быть в формате [<запрос 1>, <запрос 2>, ...]\\n\\n### ПРИМЕР (для демонстрации логики, а не для копирования)\\n- Пример входной корзины: [Мука пшеничная; Яйца куриные; Сахар-песок]\\n- Пример правильного вывода: [\"разрыхлитель\", \"ванильный экстракт\", \"сливочное масло\", \"шоколад\", \"кондитерские украшения\"]<|im_end|>\\n<|im_start|>assistant\\n[\\'Сыр твердый\\', \\'Чеснок\\', \\'Лук зеленый\\']<|im_end|>\\n'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:00:09.070258Z",
     "iopub.status.busy": "2025-11-15T10:00:09.070043Z",
     "iopub.status.idle": "2025-11-15T10:00:09.082588Z",
     "shell.execute_reply": "2025-11-15T10:00:09.081775Z",
     "shell.execute_reply.started": "2025-11-15T10:00:09.070242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# с данными что-то не то, надо чинить. Ну и вообще как будто стоит взять ноут свой рабочий да адаптировать, а не хуйней заниматься"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:00:09.083721Z",
     "iopub.status.busy": "2025-11-15T10:00:09.083414Z",
     "iopub.status.idle": "2025-11-15T10:00:09.103615Z",
     "shell.execute_reply": "2025-11-15T10:00:09.102812Z",
     "shell.execute_reply.started": "2025-11-15T10:00:09.083699Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первый пример из датасета:\n",
      "<|im_start|>system\n",
      "Ты — ИИ-ассистент для системы продуктовых рекомендаций.\n",
      "Твоя задача — анализировать корзину и генерировать идеи для поиска недостающих товаров в виде списка поисковых запросов.<|im_end|>\n",
      "<|im_start|>user\n",
      "Контекст:\n",
      "    Текущая корзина: Яйцо куриное; Грейпфрут; Салат; Майонез\n",
      "    Прошлые 5 покупок пользователя:\n",
      "    Прошлые 5 наиболее похожих покупок пользователя:\n",
      "### ЗАДАЧА\n",
      "На основе КОНТЕКСТА, сгенерируй не более 20 поисковых запросов, которые помогут пользователю добавить недостающие товары в корзину.\n",
      "Важные правила:\n",
      "1. Запросы должны быть краткими, отражать общие категории или идеи, а не конкретными товарами с брендом или весом.\n",
      "2. Не повторяй товары, которые уже есть в корзине.\n",
      "3. Поисковые запросы должны быть реалистичными для продуктового магазина с 10-15 тысячами наименований\n",
      "4. Вывод должен быть в формате [<запрос 1>, <запрос 2>, ...]\n",
      "\n",
      "### ПРИМЕР (для демонстрации логики, а не для копирования)\n",
      "- Пример входной корзины: [Мука пшеничная; Яйца куриные; Сахар-песок]\n",
      "- Пример правильного вывода: [\"разрыхлитель\", \"ванильный экстракт\", \"сливочное масло\", \"шоколад\", \"кондитерские украшения\"]<|im_end|>\n",
      "<|im_start|>assistant\n",
      "['Сыр твердый', 'Чеснок', 'Лук зеленый']<|im_end|>\n",
      "\n",
      "\n",
      "Длина текста: 1209\n",
      "Количество токенов: 324\n"
     ]
    }
   ],
   "source": [
    "print(\"Первый пример из датасета:\")\n",
    "print(dataset[0][\"text\"])\n",
    "print(f\"\\nДлина текста: {len(dataset[0]['text'])}\")\n",
    "\n",
    "# Проверка токенизации\n",
    "sample = dataset[0][\"text\"]\n",
    "tokens = tokenizer(sample, truncation=True, max_length=2048)\n",
    "print(f\"Количество токенов: {len(tokens['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:03:51.803506Z",
     "iopub.status.busy": "2025-11-15T10:03:51.803172Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n",
      "   \\\\   /|    Num examples = 123,308 | Num Epochs = 1 | Total steps = 964\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 16\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 16 x 1) = 128\n",
      " \"-____-\"     Trainable parameters = 33,030,144 of 4,040,967,680 (0.82% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='964' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  4/964 02:08 < 17:10:08, 0.02 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,   # dataset с полем \"text\" (строки)\n",
    "    eval_dataset = None,\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",           # <- важное отличие\n",
    "        per_device_train_batch_size = 8,\n",
    "        gradient_accumulation_steps = 16,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs=1,                    # или max_steps/num_train_epochs по вашей задаче\n",
    "        learning_rate = 2e-4,\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",                  # советуют в ноуте\n",
    "        weight_decay = 0.001,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        report_to = \"none\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-14T20:31:02.978455Z",
     "iopub.status.idle": "2025-11-14T20:31:02.978790Z",
     "shell.execute_reply": "2025-11-14T20:31:02.978643Z",
     "shell.execute_reply.started": "2025-11-14T20:31:02.978628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()\n",
    "print(\"Адаптеры успешно слиты.\")\n",
    "\n",
    "# Сохраняем итоговую модель для инференса.\n",
    "output_model_path = \"qwen2-4b-recipes-finetuned-float16\"\n",
    "model.save_pretrained(output_model_path)\n",
    "tokenizer.save_pretrained(output_model_path)\n",
    "\n",
    "print(f\"Полноценная модель в float16 сохранена в папку: {output_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-14T20:31:02.979928Z",
     "iopub.status.idle": "2025-11-14T20:31:02.980293Z",
     "shell.execute_reply": "2025-11-14T20:31:02.980116Z",
     "shell.execute_reply.started": "2025-11-14T20:31:02.980102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Загружаем нашу сохраненную, полноценную модель\n",
    "output_model_path = \"qwen2-4b-recipes-finetuned-float16\" # Убедитесь, что путь верный\n",
    "model_for_inference = AutoModelForCausalLM.from_pretrained(output_model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "tokenizer_for_inference = AutoTokenizer.from_pretrained(output_model_path)\n",
    "\n",
    "\n",
    "# --- Формируем тестовый промпт в формате messages ---\n",
    "test_example_input_basket = ['булочки для бургеров', 'кетчуп', 'горчица', 'лук репчатый', 'помидоры']\n",
    "current_basket_str = \"; \".join(test_example_input_basket)\n",
    "ground_truth_for_example = \"['говяжий фарш', 'сыр чеддер', 'листья салата', 'маринованные огурцы', 'картофель фри']\"\n",
    "\n",
    "# Создаем контент для юзер-промпта\n",
    "user_content_for_inference = USER_PROMPT_TEMPLATE.format(current_basket=current_basket_str)\n",
    "\n",
    "# Собираем сообщения для инференса (без ответа ассистента)\n",
    "messages_for_inference = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": user_content_for_inference},\n",
    "]\n",
    "\n",
    "# Используем токенизатор для преобразования.\n",
    "# add_generation_prompt=True, так как мы хотим, чтобы модель начала генерировать свой ответ.\n",
    "inputs = tokenizer_for_inference.apply_chat_template(\n",
    "    messages_for_inference,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\"\n",
    ").to(model_for_inference.device)\n",
    "\n",
    "\n",
    "# --- Генерируем ответ ---\n",
    "outputs = model_for_inference.generate(input_ids = inputs, max_new_tokens = 128, use_cache = True)\n",
    "# Декодируем только сгенерированную часть, исключая входной промпт\n",
    "decoded_output = tokenizer_for_inference.batch_decode(outputs[:, inputs.shape[1]:], skip_special_tokens=True)[0]\n",
    "\n",
    "\n",
    "# --- Печатаем результат ---\n",
    "print(\"--- Входная корзина ---\")\n",
    "print(test_example_input_basket)\n",
    "print(\"\\n--- Пример правильного ответа (для сравнения) ---\")\n",
    "print(ground_truth_for_example)\n",
    "print(\"\\n--- Сгенерированный ответ моделью ---\")\n",
    "print(decoded_output.strip())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8739995,
     "sourceId": 13736201,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
